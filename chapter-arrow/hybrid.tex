\section{Hybrid Bayesian Optimization}
\label{sec:arrow::hybrid}

Bayesian Optimization is an optimization framework that follows
Sequential Model-based Optimization (SMBO).
\emph{CherryPick} implements a Bayesian Optimization method that uses only instance-level information such as core counts and memory size for building the probabilistic model~\cite{Alipourfard2017}.
We call our similar implementation \emph{Naive BO}.
Our proposed method, low-level augmented Bayesian Optimization (\emph{Augment BO}) uses both high-level, instance-level information and low-level performance information.
However, the proposed \emph{Augment BO} encounters a ``slow start'' issue.
A possible explanation is the over-fitting problem---building a predictive model with high dimensional training data.

To remedy this problem, we propose a hybrid approach (Hybrid BO) that combines both Naive and Augmented BO.
The intuition here is that \emph{Naive BO} performs well when the instance-level information is able to characterize a given workload well.
This results in a small number of measurements (search cost).
When the instance-level information is not sufficient, \emph{Naive BO} may encounter the \emph{fragility} problem---either incurs higher search cost or yields a sub-optimal solution.
On the other hand, \emph{Augmented BO} is more stable and produces desirable outcomes for cases that \emph{Naive BO} does not work well.
The proposed \emph{Hybrid BO} maintains two Bayesian Optimizer at the same time.
Consequently, \emph{Hybrid BO} can produce better solutions for all cases.

The key component in \emph{Hybird BO} is the acquisition function.
\emph{Hybrid BO} uses two prediction models, one from \emph{Naive BO} and the other one from \emph{Augmented BO}.
During the search process, \emph{Hybrid BO} ``ranks'' each candidate choice.
For the high-level model, the candidates are ranked by their Expected Improvement (EI), and the predicted performance (such as execution time or deployment cost) is used in the ranking process.
\emph{Hybrid BO} uses the average rank to pick the next candidate to evaluate.
Algorithm~\ref{alg:hbo} describes the above procedure.

In practice, a stopping criterion is required for the optimizer.
Our current design is to apply separate stopping criteria to the two models.
For example, we can use $EI=10\%$ for \emph{Naive BO} and $PD=1.1$
(Performance Delta, as described in previous sections) for \emph{Augmented BO}.
If a candidate solution does not meet either the EI or PD constraint,
it is excluded from the rank process.
There exists several variants and we will leave them for future work.

\input{Chapter-Arrow/algorithm/hybrid}