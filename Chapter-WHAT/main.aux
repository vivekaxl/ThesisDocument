\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\zref@newlabel[2]{}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {3}Faster Discovery of Faster System Configurations with Spectral Learning}{9}{chapter.3}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\defcounter {refsection}{0}\relax }\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chapter:WHAT}{{3}{9}{Faster Discovery of Faster System Configurations with Spectral Learning}{chapter.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.1}Abstract}{9}{section.3.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.2}Introduction}{10}{section.3.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.3}Background \& Related Work}{11}{section.3.3}}
\newlabel{sect:addit}{{3.3}{11}{Background \& Related Work}{section.3.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.4}Approach}{13}{section.3.4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Spectral Learning}{13}{subsection.3.4.1}}
\newlabel{sect:spect}{{3.4.1}{13}{Spectral Learning}{subsection.3.4.1}{}}
\newlabel{eq:dist}{{3.2}{15}{Spectral Learning}{equation.3.4.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Spectral Sampling}{15}{subsection.3.4.2}}
\newlabel{sect:sample}{{3.4.2}{15}{Spectral Sampling}{subsection.3.4.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Regression-Tree Learning}{16}{subsection.3.4.3}}
\newlabel{rtlearning}{{3.4.3}{16}{Regression-Tree Learning}{subsection.3.4.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.5}Experiments}{16}{section.3.5}}
\newlabel{sec:experiments}{{3.5}{16}{Experiments}{section.3.5}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Research Questions}{17}{subsection.3.5.1}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Subject systems used in the experiments.\relax }}{18}{figure.caption.11}}
\newlabel{fig:systems}{{3.1}{18}{Subject systems used in the experiments.\relax }{figure.caption.11}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Subject Systems}{18}{subsection.3.5.2}}
\newlabel{sec:subject_systems}{{3.5.2}{18}{Subject Systems}{subsection.3.5.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.3}Experimental Rig}{19}{subsection.3.5.3}}
\newlabel{eq:err}{{3.3}{20}{Experimental Rig}{equation.3.5.3}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Errors of the predictions made by {\bf  WHAT }with four different sampling policies. Note that, on the y-axis, {\slswitch  lower} errors are {\slswitch  better}. \relax }}{21}{figure.caption.12}}
\newlabel{fig:sampling_accuracy}{{3.2}{21}{Errors of the predictions made by \what with four different sampling policies. Note that, on the y-axis, {\em lower} errors are {\em better}. \relax }{figure.caption.12}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.6}Results}{21}{section.3.6}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}RQ1}{21}{subsection.3.6.1}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Comparing evaluations of different sampling policies. We see that the number of configurations evaluated for $S_2$ is twice as high as $S_1$, as it selects 2 points from each cluster, where as $S_1$ selects only 1 point. \relax }}{23}{figure.caption.13}}
\newlabel{fig:Evaluations}{{3.3}{23}{Comparing evaluations of different sampling policies. We see that the number of configurations evaluated for $S_2$ is twice as high as $S_1$, as it selects 2 points from each cluster, where as $S_1$ selects only 1 point. \relax }{figure.caption.13}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.2}RQ2}{23}{subsection.3.6.2}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Standard deviations seen at various points of Figure\nobreakspace  {}\ref  {fig:sampling_accuracy}.\relax }}{24}{figure.caption.14}}
\newlabel{fig:Variance}{{3.4}{24}{Standard deviations seen at various points of \fig {sampling_accuracy}.\relax }{figure.caption.14}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.3}RQ3}{24}{subsection.3.6.3}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Solutions found by GALE, NSGA-II and DE (shown as points) laid against the ground truth (all known configuration performance scores). It can be observed that all the optimizers can find the configuration with lower performance scores.\relax }}{25}{figure.caption.15}}
\newlabel{fig:performance_graph}{{3.5}{25}{Solutions found by GALE, NSGA-II and DE (shown as points) laid against the ground truth (all known configuration performance scores). It can be observed that all the optimizers can find the configuration with lower performance scores.\relax }{figure.caption.15}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces The table shows how the minimum performance scores as found by the learners GALE, NSGA-II, and DE, vary over 20 repeated runs. Mean values are denoted $\mu $ and IQR denotes the 25th--75th percentile. A low IQR suggests that the surrogate model build by {\bf  WHAT }is stable and can be utilized by off the shelf optimizers to find performance-optimal configurations. \relax }}{26}{table.caption.16}}
\newlabel{fig:external_validity}{{3.1}{26}{The table shows how the minimum performance scores as found by the learners GALE, NSGA-II, and DE, vary over 20 repeated runs. Mean values are denoted $\mu $ and IQR denotes the 25th--75th percentile. A low IQR suggests that the surrogate model build by \what is stable and can be utilized by off the shelf optimizers to find performance-optimal configurations. \relax }{table.caption.16}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.4}RQ4}{26}{subsection.3.6.4}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Comparison of the number of the samples required with the state of the art. The grey colored cells indicate the approach which has the lowest number of samples. We notice that WHAT and Guo (2N) uses less data compared to other approaches. The high fault rate of Guo (2N) accompanied with high variability in the predictions makes WHAT our preferred method.\relax }}{28}{table.caption.18}}
\newlabel{tab:measurements}{{3.2}{28}{Comparison of the number of the samples required with the state of the art. The grey colored cells indicate the approach which has the lowest number of samples. We notice that WHAT and Guo (2N) uses less data compared to other approaches. The high fault rate of Guo (2N) accompanied with high variability in the predictions makes WHAT our preferred method.\relax }{table.caption.18}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.7}Why does it work?}{28}{section.3.7}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.1}History}{28}{subsection.3.7.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.2}Testing Technique}{29}{subsection.3.7.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.3}Evaluation}{29}{subsection.3.7.3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.8}Reliability and Validity}{30}{section.3.8}}
\newlabel{sect:construct}{{3.8}{30}{Reliability and Validity}{section.3.8}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.9}Related Work}{31}{section.3.9}}
\newlabel{sect:related}{{3.9}{31}{Related Work}{section.3.9}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.10}Conclusions}{32}{section.3.10}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Mean MRE seen in 20 repeats. Mean MRE is the prediction error as described in Equation\nobreakspace  {}\ref  {eq:err} and STDev is the standard deviation of the MREs found during multiple repeats. Lines with a a dot in the middle (e.g. \quartex {3}{13}{13}) show the mean as a round dot withing the IQR (and if the IQR is very small, only a round dot will be visible). All the results are sorted by the mean values: lower mean value of MRE is better than large mean value. The left-hand side columns \textbf  {Rank} the various techniques, smaller the value of \textbf  {Rank} better the technique e.g. in Apache, all the techniques have the same rank since their mean values are not statistically different. \textbf  {Rank} is computer using Scott-Knott, bootstrap 95\% confidence, and the A12 test. \relax }}{33}{figure.caption.17}}
\newlabel{fig:stats}{{3.6}{33}{Mean MRE seen in 20 repeats. Mean MRE is the prediction error as described in Equation~\ref {eq:err} and STDev is the standard deviation of the MREs found during multiple repeats. Lines with a a dot in the middle (e.g. \protect \quartex {3}{13}{13}) show the mean as a round dot withing the IQR (and if the IQR is very small, only a round dot will be visible). All the results are sorted by the mean values: lower mean value of MRE is better than large mean value. The left-hand side columns \textbf {Rank} the various techniques, smaller the value of \textbf {Rank} better the technique e.g. in Apache, all the techniques have the same rank since their mean values are not statistically different. \textbf {Rank} is computer using Scott-Knott, bootstrap 95\% confidence, and the A12 test. \relax }{figure.caption.17}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Intrinsic dimensionality of the subjects systems are shown on the y-axis. The number on the side is the actual dimension of the system. The intrinsic dimensionality of the systems are much lower than the actual dimensionality (number of columns in the dataset).\relax }}{34}{figure.caption.19}}
\newlabel{fig:underlying_d}{{3.7}{34}{Intrinsic dimensionality of the subjects systems are shown on the y-axis. The number on the side is the actual dimension of the system. The intrinsic dimensionality of the systems are much lower than the actual dimensionality (number of columns in the dataset).\relax }{figure.caption.19}{}}
\@setckpt{Chapter-WHAT/main}{
\setcounter{page}{35}
\setcounter{equation}{4}
\setcounter{enumi}{3}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{8}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{3}
\setcounter{section}{10}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{7}
\setcounter{table}{2}
\setcounter{lofdepth}{1}
\setcounter{lotdepth}{1}
\setcounter{r@tfl@t}{0}
\setcounter{cp@cntr}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{chapter@totc}{6}
\setcounter{parentequation}{0}
\setcounter{lips@count}{0}
\setcounter{ALC@unique}{0}
\setcounter{ALC@line}{0}
\setcounter{ALC@rem}{0}
\setcounter{ALC@depth}{0}
\setcounter{AlgoLine}{0}
\setcounter{algocfline}{0}
\setcounter{algocfproc}{0}
\setcounter{algocf}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{tabx@nest}{0}
\setcounter{listtotal}{0}
\setcounter{listcount}{0}
\setcounter{liststart}{0}
\setcounter{liststop}{0}
\setcounter{citecount}{0}
\setcounter{citetotal}{0}
\setcounter{multicitecount}{0}
\setcounter{multicitetotal}{0}
\setcounter{instcount}{93}
\setcounter{maxnames}{2}
\setcounter{minnames}{1}
\setcounter{maxitems}{3}
\setcounter{minitems}{1}
\setcounter{citecounter}{0}
\setcounter{savedcitecounter}{0}
\setcounter{uniquelist}{0}
\setcounter{uniquename}{0}
\setcounter{refsection}{0}
\setcounter{refsegment}{0}
\setcounter{maxextrayear}{0}
\setcounter{maxextraalpha}{0}
\setcounter{abbrvpenalty}{50}
\setcounter{highnamepenalty}{50}
\setcounter{lownamepenalty}{25}
\setcounter{maxparens}{3}
\setcounter{parenlevel}{0}
\setcounter{mincomprange}{10}
\setcounter{maxcomprange}{100000}
\setcounter{mincompwidth}{1}
\setcounter{labelname}{0}
\setcounter{savedlabelname}{0}
\setcounter{author}{0}
\setcounter{savedauthor}{0}
\setcounter{shortauthor}{0}
\setcounter{savedshortauthor}{0}
\setcounter{editor}{0}
\setcounter{savededitor}{0}
\setcounter{editora}{0}
\setcounter{savededitora}{0}
\setcounter{editorb}{0}
\setcounter{savededitorb}{0}
\setcounter{editorc}{0}
\setcounter{savededitorc}{0}
\setcounter{shorteditor}{0}
\setcounter{savedshorteditor}{0}
\setcounter{bookauthor}{0}
\setcounter{savedbookauthor}{0}
\setcounter{translator}{0}
\setcounter{savedtranslator}{0}
\setcounter{annotator}{0}
\setcounter{savedannotator}{0}
\setcounter{commentator}{0}
\setcounter{savedcommentator}{0}
\setcounter{introduction}{0}
\setcounter{savedintroduction}{0}
\setcounter{foreword}{0}
\setcounter{savedforeword}{0}
\setcounter{afterword}{0}
\setcounter{savedafterword}{0}
\setcounter{holder}{0}
\setcounter{savedholder}{0}
\setcounter{namea}{0}
\setcounter{savednamea}{0}
\setcounter{nameb}{0}
\setcounter{savednameb}{0}
\setcounter{namec}{0}
\setcounter{savednamec}{0}
\setcounter{institution}{0}
\setcounter{savedinstitution}{0}
\setcounter{language}{0}
\setcounter{savedlanguage}{0}
\setcounter{location}{0}
\setcounter{savedlocation}{0}
\setcounter{organization}{0}
\setcounter{savedorganization}{0}
\setcounter{origlocation}{0}
\setcounter{savedoriglocation}{0}
\setcounter{origpublisher}{0}
\setcounter{savedorigpublisher}{0}
\setcounter{pageref}{0}
\setcounter{savedpageref}{0}
\setcounter{publisher}{0}
\setcounter{savedpublisher}{0}
\setcounter{lista}{0}
\setcounter{savedlista}{0}
\setcounter{listb}{0}
\setcounter{savedlistb}{0}
\setcounter{listc}{0}
\setcounter{savedlistc}{0}
\setcounter{listd}{0}
\setcounter{savedlistd}{0}
\setcounter{liste}{0}
\setcounter{savedliste}{0}
\setcounter{listf}{0}
\setcounter{savedlistf}{0}
\setcounter{textcitecount}{0}
\setcounter{textcitetotal}{0}
\setcounter{textcitemaxnames}{0}
\setcounter{biburlnumpenalty}{0}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{0}
\setcounter{smartand}{1}
\setcounter{bbx:relatedcount}{0}
\setcounter{bbx:relatedtotal}{0}
\setcounter{cbx@tempcnta}{0}
\setcounter{cbx@tempcntb}{33}
\setcounter{tm@util}{0}
\setcounter{List1}{0}
\setcounter{List2}{0}
\setcounter{List3}{0}
\setcounter{List4}{0}
\setcounter{List5}{0}
\setcounter{List6}{0}
\setcounter{List7}{0}
\setcounter{List8}{0}
\setcounter{List9}{0}
\setcounter{List10}{0}
\setcounter{lstnumber}{1}
\setcounter{Item}{6}
\setcounter{Hfootnote}{9}
\setcounter{bookmark@seq@number}{35}
\setcounter{mdf@globalstyle@cnt}{1}
\setcounter{mdfcountframes}{0}
\setcounter{mdf@env@i}{0}
\setcounter{mdf@env@ii}{0}
\setcounter{mdf@zref@counter}{0}
\setcounter{ncsu@appendixtocdepth}{2}
\setcounter{lstlisting}{0}
\setcounter{section@level}{0}
}
