\section{Design Choices}
\label{sec:design}

\begin{figure}
\resizebox{.8\linewidth}{!}{%
    \small{
        \begin{tabular}{@{}lccccc@{}}
        \toprule
        \textbf{Methods} & \textbf{\begin{tabular}[c]{@{}c@{}}Search-\\ based\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Relative\\ Ordering\end{tabular}}  & \textbf{\begin{tabular}[c]{@{}c@{}}Low-level\\ Metrics\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Historical\\ Data\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Transfer\\ Learning\end{tabular}} \\ \midrule
        CherryPick~\cite{Alipourfard2017} & \cmark & \xmark & \xmark & \xmark & \xmark \\
        PARIS~\cite{Yadwadkar2017} & \xmark & \xmark & \cmark & \cmark & \xmark \\
        Arrow~\cite{Hsu2018Arrow} & \cmark & \xmark & \cmark & \xmark & \xmark \\
        \cellcolor[HTML]{9B9B9B}\textcolor{white}{\textbf{Scout}} & \cellcolor[HTML]{9B9B9B}\color{white}\cmark & \cellcolor[HTML]{9B9B9B}\color{white}\cmark & \cellcolor[HTML]{9B9B9B}\color{white}\cmark & \cellcolor[HTML]{9B9B9B}\color{white}\cmark & \cellcolor[HTML]{9B9B9B}\color{white}\cmark \\ %\bottomrule
        \end{tabular}
    }
    }
    \centering
    \caption{
    \small{
    \textbf{An overall comparison with other CAT methods.}
    A search-based method better tolerates prediction bias.
    Relative ordering better captures the workload-architecture-performance relationship.
    Leveraging low-level metrics improves search performance.
    Historical data helps eliminate unnecessary exploration overhead in a search.
    Transfer learning greatly reduces search cost.}
    }
    \label{fig:model_classification}
\end{figure}


By analyzing the differences between the state of the art methods,
we identified the following key components in solving the CAT problem:
(1) a search-based method (similar to \emph{Cherrypick}~\cite{Alipourfard2017})
is essential since it accommodates mispredictions and performance variances
in the cloud,
(2) relative ordering better captures
the workload-architecture-performance relationship,
which creates fewer mispredictions,
(3) low-level performance metrics are a good proxy of
predicting system performance~\cite{Novakovic2013,Hsu2016,Yadwadkar2017},
(4) historical data (as used in PARIS~\cite{Yadwadkar2017}) is useful
to understand the inherent preferences of a workload, and
(5) transfer learning boosts search performance and improves convergence speed
by minimizing exploration phase.
These components together solve the CAT problem more effectively
and overcome the shortcomings of the current state of the art approaches.
\myfigure{\ref{fig:model_classification}} compares and contrasts the
design choices of \scout against prior work.

Because it is a daunting task to build an accurate model that
predicts performance and cost of workloads on
distinct cloud architectural configurations,
we can instead build an indirect model (for improving prediction accuracy).
A search-based method does not require a direct answer
(which choice is the best),
but an answer to ``are there better choices?''
We do not predict the absolute performance of a configuration but rather
predict the relative performance of two configurations.
That is, we can simplify the prediction model that will assist
a search-based method in finding the solutions more efficiently~\cite{nair2017}.
\emph{Learning to rank} is an important machine learning task
~\cite{harrell2001ordinal,li2008mcrank,cao2007learning}.
We prefer relative ordering instead of total ordering for
ranking architectural configurations because
there does not exist a one-size-fits-all architecture
for any workloads and for any objectives.

SMBO requires exploration efforts
(increases search cost)
to update its belief (prediction) on the search space.
However, the data for the initial model need not come from
the workload being evaluated.
Rather, data from any workload can be used to build a useful model describing
the search space.
For this model to be most useful, the information must be generic---independent
of workloads.
This technique is inspired by \cite{Hsu2016,Yadwadkar2017}.
There are too few features (dimensions and options) in the configuration space
to build a robust model that works across many workloads.
Consequently, a model based only on architectural features
(\eg{cluster sizes and memory per core}) is fragile.

To summarize, the following elements are necessary
to create an effective approach.
\begin{enumerate}[leftmargin=*]
    \setlength\itemsep{-0.4em}
    \item Prefer the \textbf{\textit{search-based technique}}, which converges to the best solution iteratively and avoids the large penalty caused by dramatic prediction error.
    \item Use a \textbf{\textit{relaxed}} model that boosts prediction accuracy, thereby better guides a search process to find the near-optimal configurations more quickly,
    \item Use \textbf{\textit{low-level metrics}} to generate a generic representation of the search space such that it can be used by other combinations of workload and application.
    \item Create a \textbf{\textit{performance database}} so that the knowledge of optimization can be used by other optimizers to find the right cloud configuration and hence reduce the search cost. 
\end{enumerate}